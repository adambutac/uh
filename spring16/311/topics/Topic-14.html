<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html> <head>
<title>ICS 311 #14: Graphs </title>
</head>

<body>

<hr><h1><a href="../index.html">ICS 311</a> #14: Graphs </h1>
<h2>Representations, Search, and Connectivity</h2><hr> 

<!-- ------------------------------------------------------------ -->
<h2>Outline</h2>
<p>Tuesday</p> 
<ol>
  <li>Graph Definitions &amp; examples</li>
  <li>Graph ADT</li>
  <li>Representations (Implementations) of Graph ADT</li>
  <li>Breadth-first Search </li>
</ol>
<p>Thursday</p> 
<ol>
  <li>Depth-first Search </li>
  <li>Topological Sort </li>
  <li>Strongly Connected Components </li>
  <li>Related Concepts </li>
</ol>

<h2>Readings and Screencasts</h2>
<ul>
  <li>Required: CLRS 3rd Ed. Chapter 22, Elementary Graph Algorithms, entire chapter.</li>
  <li>See also: Sedgewick (1984) Chapter 32 for light conceptual introduction (in Laulima).</li> 
  <li>Screencasts <a href="http://youtu.be/IdStgDmUlXM">14A</a>, 
                  <a href="http://youtu.be/pyDxf58rK_0">14B</a>,
                  <a href="http://youtu.be/A8SKOFseOyU">14C</a>,
                  <a href="http://youtu.be/emiWSGizJlc">14D</a>,
                  <a href="http://youtu.be/HMPaUoGfsPo">14E</a>,
                  <a href="http://youtu.be/TZDQHplPrNo">14F</a>
                  (also in Laulima and iTunesU)</li>
</ul>
  
<p>The video lectures and notes below provide material not found in the textbook: defining graphs,
an ADT, and implementations.</p>


<!-- ------------------------------------------------------------ -->
<hr><h2> Graphs </h2>

<h3>Definitions</h3>
<p>A graph <i>G</i> is a pair</p>
<blockquote><big><i>G</i> = (<i>V</i>, <i>E</i>)</big></blockquote>
<p>where </p> 
<blockquote><big><i>V</i> = {<i>v</i><sub>1</sub>, <i>v</i><sub>2</sub>,
  ... <i>v</i><sub>n</sub>},</big> a set of <b>vertices</b></blockquote> 
<blockquote><big><i>E</i> = {<i>e</i><sub>1</sub>, <i>e</i><sub>2</sub>, ... <i>e</i><sub>m</sub>}
  &sube; <i>V</i> &otimes; <i>V</i></big>, a set of <b>edges</b>.</blockquote> 

<h4>Undirected Graphs</h4> 
<p>In an <b>undirected graph</b> the edge set E consists of <i>unordered pairs</i> of vertices. That
is, they are sets <i>e</i> = {<i>u</i>, <i>v</i>}. Edges can be written with this notation when clarity is
desired, but we will often use parentheses (<i>u</i>, <i>v</i>).

<p>No self loops are allowed in undirected graphs. That is, we cannot have (<i>v</i>, <i>v</i>),
which would not make as much sense in the set notation {<i>v</i>, <i>v</i>}.</p>

<p>We say that <i>e</i> = {<i>u</i>, <i>v</i>} is <b>incident on</b> <i>u</i> and <i>v</i>, and that
the latter vertices are <b>adjacent</b>. The <b>degree</b> of a vertex is the number of edges
incident on it.</p>

<p>The <b>handshaking lemma</b> is often useful in proofs:</p>
<blockquote>
<big>&Sigma;</big><sub><i>v</i>&in;<i>V</i></sub>degree(<i>v</i>) = 2|<i>E</i>|
</blockquote>
<p>(Each edge contributes two to the sum of degrees.) </p>

<h4>Directed Graphs</h4>

<p>In a <b>directed graph</b> or <b>digraph</b> the edges are ordered pairs (<i>u</i>,
<i>v</i>).</p> 

<p>We say that <i>e</i> = (<i>u</i>, <i>v</i>) is <b>incident from</b> or <b>leaves</b> <i>u</i> and
is <b>incident to</b> or <b>enters</b> <i>v</i>. The <b>in-degree</b> of a vertex is the number of
edges incident to it, and the <b>out-degree</b> of a vertex is the number of edges incident from
it.</p>

<p><b>Self loops</b> (<i>v</i>, <i>v</i>) are allowed in directed graphs.</p> 

<h4>Paths</h4>

<p>A <b>path</b> of length <i>k</i> is a sequence of vertices &lang;<i>v</i><sub>0</sub>,
<i>v</i><sub>1</sub>, <i>v</i><sub>2</sub>, ... <i>v</i><sub>k</sub>&rang; where
(<i>v</i><sub><i>i</i>-1</sub>, <i>v</i><sub><i>i</i></sub>) &in; <i>E</i>, for <i>i</i> = 1, 2,
... <i>k</i>. (Some authors call this a "walk".) The path is said to <b>contain</b> the vertices and
edges just defined.</p>

<p>A <b>simple path</b> is a path in which all vertices are distinct. (The "walk" authors call this
a "path").</p>

<p>If a path exists from <i>u</i> to <i>v</i> we say that <i>v</i> is <b>reachable</b> from <i>u</i>.</p> 

<p>In an undirected graph, a path &lang;<i>v</i><sub>0</sub>, <i>v</i><sub>1</sub>,
<i>v</i><sub>2</sub>, ... <i>v</i><sub>k</sub>&rang; forms a <b>cycle</b> if <i>v</i><sub>0</sub> =
<i>v</i><sub>k</sub> and <i>k</i> &ge; 3 (as no self-loops are allowed). </p>

<p>In a directed graph, a path forms a <b>cycle</b> if <i>v</i><sub>0</sub> = <i>v</i><sub>k</sub>
and the path contains at least one edge. (This is clearer than saying that the path contains at
least two vertices, as self-loops are possible in directed graphs.) The cycle is <b>simple</b> if
<i>v</i><sub>1</sub>, <i>v</i><sub>2</sub>, ... <i>v</i><sub>k</sub> are distinct (i.e., all but the
designated start and end <i>v</i><sub>0</sub> = <i>v</i><sub>k</sub> are distinct). A directed graph
with no self-loops is also <b>simple</b>.</p>

<p>A graph of either type with no cycles is <b>acyclic</b>. A directed acyclic graph is often called
a <b>dag</b>.</p> 

<h4>Connectivity</h4>

<p> A graph <i>G'</i> = (<i>V'</i>, <i>E'</i>) is a <b>subgraph</b> of <i>G</i> = (<i>V</i>,
<i>E</i>) if <i>V'</i> &sube; <i>V</i> and  <i>E'</i> &sube; <i>E</i>. </p> 

<p>An undirected graph is <b>connected</b> if every vertex is reachable from all other vertices. In
any connected undirected graph, |<i>E</i>| &ge; |<i>V</i>| - 1 (see also <a
 href="Topic-08.html">discussion of tree properties</a>). The <b>connected components</b> of
<i>G</i> are the maximal subgraphs <i>G</i><sub>1</sub> ... <i>G</i><sub><i>k</i></sub> where every
vertex in a given subgraph is reachable from every other vertex in that subgraph, but not reachable
from any vertex in a different subgraph.</p>

<p>A directed graph is <b>strongly connected</b> if every two vertices are reachable from each
other. The <b>strongly connected components</b> are the subgraphs defined as above. A directed graph
is thus strongly connected if it has only one strongly connected component. A directed graph
is <b>weakly connected</b> if the underlying undirected graph (converting all tuples (<i>u</i>,
<i>v</i>) &in; <i>E</i> into sets {<i>u</i>, <i>v</i>} and removing self-loops) is connected. </p>

<p></p>

<h4>Variations</h4>

<p>A <b>bipartite</b> graph is one in which <i>V</i> can be partitioned into two sets
<i>V</i><sub>1</sub> and <i>V</i><sub>2</sub> such that every edge connects a vertex in
<i>V</i><sub>1</sub> to one in <i>V</i><sub>2</sub>. Equivalently, there are no odd-length
cycles.</p>

<p>A <b>complete</b> graph is an undirected graph in which every pair of vertices is adjacent.</p> 

<p>A <b>weighted</b> graph has numerical weights associated with the edges. (The allowable values
depend on the application. Weights are often used to represent distance, cost or capacity in
networks.)</p> 

<h3>Graph Size in Analysis</h3> 
<p>Asymptotic analysis is often in terms of both |<i>V</i>| and |<i>E</i>|. Within asymptotic
notation we leave out the "|" for simplicity, for example, writing O(<i>V</i> + <i>E</i>),
O(<i>V</i><sup>2</sup> lg <i>E</i>), etc.</p>

<h3>Many Applications ... </h3> 
<img src="Topic-14/GT-Map-Graph-Example.jpg">
<img src="Topic-14/GT-Circuit-Graph-Example.jpg">
<img src="Topic-14/social-network.jpg">
<img src="Topic-14/240px-Internet_map_1024.jpg"> 

<!-- ------------------------------------------------------------ -->
<hr><h2>Graph ADT</h2>

<p>These are detailed slightly more in <a href="../Projects/Project-2.html">Project 2</a>, and in
the Goodrich & Tamassia excerpt uploaded to Laulima.</p> 

<h4>Graph Accessors</h4>
<p><b>numVertices()</b></br>
&nbsp; &nbsp;  Returns the number of vertices |<i>V</i>|</p>
<p><b>numEdges()</b> </br>
&nbsp; &nbsp;  Returns the number of edges |<i>E</i>|</p>
<p><b>vertices()</b></br>
&nbsp; &nbsp;  Returns an iterator over the vertices <i>V</i></p>
<p><b>edges()</b></br>
&nbsp; &nbsp;  Returns an iterator over the edges <i>E</i></p>

<h4>Accessing Undirected Graphs</h4>
<p><b>degree(<i>v</i>)</b><br>
&nbsp; &nbsp;  Returns the number of edges (directed and undirected) incident on <i>v</i>.</p>
<p><b>adjacentVertices(<i>v</i>)</b></br>
&nbsp; &nbsp;  Returns an iterator of the vertices adjacent to <i>v</i>.</p>
<p><b>incidentEdges(<i>v</i>)</b></br>
&nbsp; &nbsp;  Returns an iterator of the edges incident on <i>v</i>. </p>
<p><b>endVertices(<i>e</i>)</b></br>
&nbsp; &nbsp;  Returns an array of the two end vertices of <i>e</i>.</p>
<p><b>opposite(<i>v</i>,<i>e</i>)</b></br>
&nbsp; &nbsp;  Given <i>v</i> is an endpoint of <i>e</i>.<br>
&nbsp; &nbsp;  Returns the end vertex of <i>e</i> different from <i>v</i>. <br>
&nbsp; &nbsp;  Throws InvalidEdgeException when <i>v</i> is not an endpoint of <i>e</i>.</p>
<p><b>areAdjacent(<i>v</i><sub>1</sub>,<i>v</i><sub>2</sub>)</b></br>
&nbsp; &nbsp; Returns true iff <i>v</i><sub>1</sub> and <i>v</i><sub>2</sub> are adjacent by a
single edge. </p> 

<h4> Accessing Directed Graphs </h4>
<p><b>directedEdges()</b></br>
&nbsp; &nbsp;  Returns an iterator over the directed edges of <i>G</i>. </p>
<p><b>undirectedEdges()</b></br>
&nbsp; &nbsp;  Returns an iterator over the undirected edges of <i>G</i>. </p>
<p><b>inDegree(<i>v</i>)</b></br>
&nbsp; &nbsp;  Returns the number of directed edges (arcs) incoming to <i>v</i>. </p>
<p><b>outDegree(<i>v</i>)</b><br>
&nbsp; &nbsp;  Returns the number of directed edges (arcs) outgoing from <i>v</i>.</p>
<p><b>inAdjacentVertices(<i>v</i>)</b></br>
&nbsp; &nbsp;  Returns an iterator over the vertices adjacent to <i>v</i> by incoming edges. </p>
<p><b>outAdjacentVertices(<i>v</i>)</b></br>
&nbsp; &nbsp;  Returns an iterator over the vertices adjacent to <i>v</i> by outgoing edges. </p>
<p><b>inIncidentEdges(<i>v</i>)</b></br>
&nbsp; &nbsp;  Returns an iterator over the incoming edges of <i>v</i>. </p>
<p><b>outIncidentEdges(<i>v</i>)</b></br>
&nbsp; &nbsp;  Returns an iterator over the outgoing edges of <i>v</i>. </p>
<p><b>destination(<i>e</i>)</b></br>
&nbsp; &nbsp; Returns the destination vertex of <i>e</i>, if <i>e</i> is directed.<br>
&nbsp; &nbsp; Throws InvalidEdgeException when <i>e</i> is undirected.</p>
<p><b>origin(<i>e</i>)</b></br>
&nbsp; &nbsp;  Returns the origin vertex of <i>e</i>, if <i>e</i> is directed.<br>
&nbsp; &nbsp;  Throws InvalidEdgeException when <i>e</i> is undirected. </p>
<p><b>isDirected(<i>e</i>)</b></br>
&nbsp; &nbsp;  Returns true if <i>e</i> is directed, false otherwise</p>

<h4>Mutators (Undirected and Directed)</h4> 
<p><b>insertEdge(<i>u</i>,<i>v</i>)</b></br>
<b>insertEdge(<i>u</i>,<i>v</i>,<i>o</i>)</b></br>
&nbsp; &nbsp;  Inserts a new undirected edge between two existing vertices, optionally containing
object <i>o</i>.<br>
&nbsp; &nbsp;  Returns the new edge. </p>
<p><b>insertVertex()</b></br>
<b>insertVertex(<i>o</i>)</b></br>
&nbsp; &nbsp;  Inserts a new isolated vertex optionally containing an object <i>o</i> (e.g., the
label associated with the vertex).<br>
&nbsp; &nbsp;  Returns the new vertex. </p>
<p><b>insertDirectedEdge(<i>u</i>,<i>v</i>)</b></br>
<b>insertDirectedEdge(<i>u</i>,<i>v</i>,<i>o</i>)</b></br>
&nbsp; &nbsp;  Inserts a new directed edge from an existing vertex to another.<br>
&nbsp; &nbsp;  Returns the new edge. </p>
<p><b>removeVertex(<i>v</i>)</b></br>
&nbsp; &nbsp;  Deletes a vertex and all its incident edges.<br>
&nbsp; &nbsp;  Returns object formerly stored at <i>v</i>.</p>
<p><b>removeEdge(<i>e</i>)</b></br>
&nbsp; &nbsp;  Removes an edge.<br>
&nbsp; &nbsp;  Returns the object formerly stored at <i>e</i>.</p>

<h4>Annotators (for vertices and all types of edges)</h4>
<p>Methods for annotating vertices and edges with arbitrary data.</p>
<p><b>setAnnotation(Object <i>k</i>, <i>o</i>)</b></br>
&nbsp; &nbsp; Annotates a vertex or edge with object <i>o</i> indexed by key <i>k</i>.</p>
<p><b>getAnnotation(Object <i>k</i>)</b></br>
&nbsp; &nbsp; Returns the object indexed by <i>k</i> annotating a vertex or edge.</p>
<p><b>removeAnnotation(Object <i>k</i>)</b></br>
&nbsp; &nbsp; Removes the annotation on a vertex or edge indexed by <i>k</i> and returns it.</p>  

<h4>Changing Directions</h4>
<p>There are various methods for changing the direction of edges. I think the only one we will need
is:</p>
<p><b>reverseDirection(<i>e</i>)</b></br>
&nbsp; &nbsp;  Reverse the direction of an edge.<br>
&nbsp; &nbsp;  Throws InvalidEdgeException if the edge is undirected</p>


<!-- ------------------------------------------------------------ -->
<hr><h2> Graph Representations </h2>

<p>There are two classic representations: the adjacency list and the adjacency matrix.</p>

<p>In the <b>adjacency list</b>, vertices adjacent to vertex <i>v</i> are listed explicitly on
linked list <i>G</i>.Adj[<i>v</i>] (assuming an array representation of list headers).</p>

<p>In the <b>adjacency matrix</b>, vertices adjacent to vertex <i>v</i> are indicated by nonzero
entries in the row of the matrix indexed by v, in the columns for the adjacent vertices.</p>

<p>Adjacency List and Matrix representations of an undirected graph:</p> 
<img src="Topic-14/Fig-22-1-representations-undirected.jpg">

<p>Adjacency List and Matrix representations of a directed graph:</p> 
<img src="Topic-14/Fig-22-2-representations-directed.jpg">

<p><i>Consider this before reading on: What are the asymptotic complexities of these methods in each
representation? </i></p>
<ul>
  <li> List vertices/edges
  <li> areAdjacent
  <li> access (out)AdjacentVertices or (out)IncidentEdges (outdegree)
  <li> access (in)AdjacentVertices or (in)IncidentEdges (indegree)
</ul> 

<p><i>Are edges first class objects in the above representations? Where do you store edge
information in the undirected graph representations?</i></p>

<!-- --------------------------------- -->
<h3>Complexity Analysis</h3> 
<h4>Adjacency List</h4> 
<p>Space required: &Theta;(<i>V</i> + <i>E</i>).</p>
<p>Time to list all vertices adjacent to u: &Theta;(degree(<i>u</i>)).</p>
<p>Time to determine whether (<i>u</i>, <i>v</i>) &in; <i>E</i>: O(degree(<i>u</i>)).</p>

<h4>Adjacency Matrix</h4>
<p>Space required: &Theta;(<i>V</i><sup>2</sup>).</p>
<p>Time to list all vertices adjacent to <i>u</i>: &Theta;(<i>V</i>).</p>
<p>Time to determine whether (<i>u</i>, <i>v</i>) &in; <i>E</i>: &Theta;(1).</p>

<p>So the matrix takes more space and more time to list adjacent matrices, but is faster to test
adjacency of a pair of matrices. </p>

<!-- --------------------------------- -->
<h3>"Modern" Adjacency Representation</h3>

<p>Goodrich & Tamassia (reading in Laulima) propose a representation that combines an edge list, a
vertex list, and an adjacency list for each vertex: </p> 
<img src="Topic-14/GT-adjacency-list-structure.jpg">

<p> The sets <i>V</i> and <i>E</i> can be represented using a dictionary ADT (from Implementation
Project #1). In many applications, it is especially important for <i>V</i> to enable fast access by
key, and may be important to access in order. Each vertex object has an adjacency list <i>I</i> (I
for incident), and the edges reference both the vertices they connect and the entries in this
adjacency list. There's a lot of pointers to maintain, but this enables fast access in any direction
you need, and for large sparse graphs the memory allocation is still less than for a matrix
representation.</p>

<p>See also Newman (2010) chapter 9, posted in Laulima, for discussion of graph representations.</p> 

<!-- ------------------------------------------------------------ -->
<hr><h2>BFS and DFS Overview</h2>

<p>Before starting with Cormen et al.'s more complex presentation, let's discuss how BFS and DFS can
be implemented with nearly the same algorithm, but using a queue for BFS and a stack for DFS. You
should be comfortable with this relationship between BFS/queues and DFS/stacks.</p>

<p>Sketch of both algorithms:</p>
<ol>
  <li>Pick a starting vertex and put it on the queue (BFS) or stack (DFS) </li>
  <li>Repeat until the queue/stack is empty:</li>
    <ol>
      <li>Dequeue (BFS) or pop (DFS) the next vertex <i>v</i> from the appropriate data structure</li>
      <li>If <i>v</i> is unvisited,
          <ul>
            <li>Mark <i>v</i> as visited (and process it as needed for the
          specific application). </li> 
          <li>Find the unvisted neighbors of <i>v</i> and queue
          (BFS) or push (DFS) them on the appropriate data structure.  </li>
        </ul>
      </li> 
    </ol>
</ol>


<p>Try starting with vertex q and run this using both a stack and a queue:</p>

<img src="Topic-14/small-example-digraph.jpg"> &nbsp; &nbsp; &nbsp; &nbsp;
<img src="Topic-14/small-example-digraph.jpg">

<p>BFS's FIFO queue explores nodes at each distance before going to the next distance. DFS's LIFO
stack explores the more distant neighbors of a node before continuing with nodes at the same
distance ("goes deep").</p>

<p>Search in a directed graph that is weakly but not strongly connected may not reach all vertices.</p>

<!-- ------------------------------------------------------------ -->
<hr><h2>Breadth-first Search</h2>

<p>Given a graph <i>G</i> = (<i>V</i>,<i>E</i>) and a source vertex <i>s</i> &in; <i>V</i>, output
<i>v.d</i>, the shortest distance (# edges) from <i>s</i> to <i>v</i>, for all <i>v</i> &in;
<i>V</i>. Also record <i>v.&pi;</i> = <i>u</i> such that (<i>u</i>,<i>v</i>) is the last edge on a
shortest path from <i>s</i> to <i>v</i>. (We can then trace the path back.)</p>

<p><i>Analogy</i> Send a "tsunami" out from <i>s</i> that first reaches all vertices 1 edge from
<i>s</i>, then from them all vertices 2 edges from <i>s</i>, etc. Like a tsunami, equidistant
destinations are reached at the "same time".</p>

<p>Use a FIFO queue <i>Q</i> to maintain the wavefront, such that <i>v</i> &in; <i>Q</i> iff the
tsunami has hit <i>v</i> but has not come out of it yet.</p>

<img src="Topic-14/bfs-nature-of-computation.jpg" align="right"> 
<img src="Topic-14/pseudocode-BFS.jpg">

<p>At any given time <i>Q</i> has vertices with <i>d</i> values <i>i, i, ... i, i+1, i+1,
... i+1</i>. That is, there are at most two distances on the queue, and values increase monotonically.</p>

<!-- --------------------------------- -->
<h3>Examples</h3> 
<h4>Book's Example: Undirected Graph</h4>
<img src="Topic-14/Fig-22-3-operation-BFS.jpg">

<h4>A directed example:</h4> 
<p>Let's do another (number the nodes by their depth, then click to compare your answer):</p> 
<a href="Topic-14/BFS-directed-graph-example-2.jpg"><img src="Topic-14/BFS-directed-graph-example-1.jpg"></a>

<!-- --------------------------------- -->
<h3>Time Analysis</h3>

<p>(This is an aggregate analysis.) Every vertex is enqueued at most once. We examine edge
(<i>u</i>, <i>v</i>) only when <i>u</i> is dequeued, so every edge is examined at most once if
directed and twice if undirected. Therefore, O(<i>V</i> + <i>E</i>).</p>

<!-- --------------------------------- -->
<h3>Shortest Paths</h3>

<p><b>Shortest distance</b> &delta;(<i>s</i>, <i>v</i>) from <i>s</i> to <i>v</i> is the minimum
number of edges across all paths from <i>s</i> to <i>v</i>, or &infin; if no such path exists.</p>

<p>A <b>shortest path</b> from <i>s</i> to <i>v</i> is a path of length  &delta;(<i>s</i>,
<i>v</i>).</p>

<p>It can be shown that BFS is guaranteed to find the shortest paths to all vertices from a start
vertex <i>s</i>: <i>v</i>.<i>d</i> = &delta;(<i>s</i>, <i>v</i>), &forall; <i>v</i> at the
conclusion of the algorithm. See book for tedious proof.</p>

<p>Informally, we can see that all vertices at distance 1 from <i>s</i> are enqueued first, then
via them all nodes of distance 2 are reached and enqueued, etc., so inductively it would be a
contradiction if BFS reached a vertex <i>c</i> by a longer path than the shortest path because the
last vertex <i>u</i> on the shortest path to the given vertex <i>v</i> would have been enqueued
first and then dequeued to reach <i>v</i>. </p>

<!-- --------------------------------- -->
<h3>Breadth-First Trees</h3>

<p>The <b>predecessor subgraph</b> of G is </p>
<blockquote>
G<sub>&pi;</sub> = (V<sub>&pi;</sub>, E<sub>&pi;</sub>) where <br>
V<sub>&pi;</sub>= {<i>v</i> &in; V : <i>v</i>.&pi; &ne; NIL} &cup; {<i>s</i>} and <br>
E<sub>&pi;</sub> = {(<i>v</i>.&pi;, <i>v</i>) : <i>v</i> &in; V<sub>&pi;</sub> - {<i>s</i>}}
</blockquote>

<p>A predecessor subgraph G<sub>&pi;</sub> is a <b>breadth-first tree</b> if V<sub>&pi;</sub>
consists of exactly all vertices reachable from <i>s</i> and for all <i>v</i> in V<sub>&pi;</sub>
the subgraph G<sub>&pi;</sub> contains unique simple and <em> shortest</em> paths from <i>s</i> to
<i>v</i>. </p>

<p>BFS constructs &pi; such that G<sub>&pi;</sub> is a breadth-first tree.</p> 

<!-- ------------------------------------------------------------ -->
<hr><h2>Depth-first Search </h2>

<p>Given <i>G</i> = (<i>V</i>, <i>E</i>), directed or undirected, DFS explores the graph from every
vertex (no source is vertex given), constructing a <em>forest</em> of trees and recording two time
stamps on each vertex:</p>

<ul>
  <li><i>v.d</i> = discovery time</li>
  <li><i>v.f</i> = finishing time</li>
</ul>

<p>Time starts at 0 before the first vertex is visited, and is incremented by 1 for every
discovery and finishing event (as explained below). These attributes will be used in other
algorithms later on.</p>

<p>Since each vertex is discovered once and finished once, discovery and finishing times are unique
integers from 1 to 2|<i>V</i>|, and for all <i>v</i>, <i>v.d</i> &lt; <i>v.f</i>. </p>

<p><i>(Some presentations of DFS pose it as a way to visit nodes, enabling a given method to be applied
to the nodes with no output specified. Others present it as a way to construct a tree. The CLRS 
presentation is more complex but supports a variety of applications.)</i></p>

<p>DFS explores <i>every</i> edge and starts over from different vertices if necessary to reach them
(unlike BFS, which may fail to reach subgraphs not connected to <i>s</i>).</p>

<p>As it progresses, every vertex has a color:</p>
<blockquote> 
<dl>
  <dt>WHITE = undiscovered</dt><br>
  <dt>GRAY = discovered, but not finished (still exploring vertices reachable from it)</dt>
  <dd><i>v</i>.<i>d</i> records the moment at which <i>v</i> is <em>discovered</em> and colored
      gray.</dd> <br>
  <dt>BLACK = finished (have found everything reachable from it)</dt> 
  <dd><i>v</i>.<i>f</i> records the moment at which <i>v</i> is <em>finished</em> and colored 
      black.</dd>
</dl>
</blockquote>

<img src="Topic-14/dfs-nature-of-computation.jpg" align="right">

<h3>Pseudocode</h3>

<img src="Topic-14/pseudocode-DFS.jpg">
<img src="Topic-14/pseudocode-DFS-Visit.jpg">

<p>While BFS uses a queue, DFS operates in a stack-like manner (using the implicit recursion stack
in the algorithm above).</p>
<ul>
  <li>BFS's FIFO queue explores nodes at each distance before going to the next
      distance</li>
  <li>DFS's implicit LIFO stack explores the more distant neighbors of a node before 
      continuing with nodes at the same distance ("goes deep").</li>
</ul> 

<p>Another major difference in the algorithms as presented here is that DFS will search from every
vertex until all edges are explored, while BFS only searches from a designated start vertex.</p>
<ul>
  <li> This is not an essential difference: both could be either restricted to a start vertex or run
    from all vertices; </li> 
  <li> This reflects how the algorithms are used in practice (BFS for finding shortest paths; DFS
    for exposing structure of the graph, as will be explained shortly). </li>
</ul>

<h3>Example:</h3>

<p>One could start DFS with any arbitrary vertex, and continue at any remaining vertex after the
first tree is constructed. Regularities in the book's examples (e.g., processing vertices in
alphabetical order, or always starting at the top of the diagram) do not reflect a requirement of
the algorithm.</p>

<img src="Topic-14/Fig-22-4-operation-DFS-a.jpg">
<img src="Topic-14/Fig-22-4-operation-DFS-b.jpg">
<img src="Topic-14/Fig-22-4-operation-DFS-c.jpg">
<img src="Topic-14/Fig-22-4-operation-DFS-d.jpg">
<img src="Topic-14/Fig-22-4-operation-DFS-e.jpg">
<img src="Topic-14/Fig-22-4-operation-DFS-f.jpg">
<img src="Topic-14/Fig-22-4-operation-DFS-g.jpg">
<img src="Topic-14/Fig-22-4-operation-DFS-h.jpg">
<img src="Topic-14/Fig-22-4-operation-DFS-i.jpg">
<img src="Topic-14/Fig-22-4-operation-DFS-j.jpg">
<img src="Topic-14/Fig-22-4-operation-DFS-k.jpg">
<img src="Topic-14/Fig-22-4-operation-DFS-l.jpg">
<img src="Topic-14/Fig-22-4-operation-DFS-m.jpg">
<img src="Topic-14/Fig-22-4-operation-DFS-n.jpg">
<img src="Topic-14/Fig-22-4-operation-DFS-o.jpg">
<img src="Topic-14/Fig-22-4-operation-DFS-p.jpg">

<p>Let's do this example (start with the upper left node, label the nodes with their d and f, then
click to compare your answer):</p>  
<a href="Topic-14/DFS-directed-graph-example-1.jpg"><img
src="Topic-14/DFS-directed-graph-example-0.jpg"></a>

<h4>Time Analysis</h4>

<img src="Topic-14/pseudocode-DFS-DFS-Visit.jpg" align="right">

<p>The analysis uses aggregate analysis, and is similar to the BFS analysis, except that DFS is guaranteed to visit every vertex and edge, so it is
&Theta; not O:</p>

<blockquote>
&Theta;(<i>V</i>) to visit all vertices in lines 1 and 5 of <tt>DFS</tt>;<br><br> 
<big>&Sigma;</big><sub><i>v</i>&in;<i>V</i></sub> |Adj(<i>v</i>)| = &Theta;(<i>E</i>) to process the
adjacency lists in line 4 of <tt>DFS-Visit</tt>. <br><br>
(<em>Aggregate analysis:</em> we are not attempting to count how many times the loop of line 4
executes each time it is encountered, as we don't know |Adj(<i>v</i>)|. Instead, we sum the number of
passes through the loop in total: all edges will be processed.) <br><br>
The rest is constant time. 
</blockquote>

<p> Therefore, &Theta;(<i>V</i> + <i>E</i>). </p>

<h3>Classification of Edges</h3>
<p>This classification will be useful in forthcoming proofs and algorithms. </p> 
<ul>
  <li><b>Tree Edge</b>: in the <b>depth-first forest</b> constructed by DFS: found by exploring
      (<i>u</i>,<i>v</i>). </li>
  <li><b>Back Edge</b>: (<i>v</i>,<i>u</i>), where <i>v</i> is a descendant of <i>u</i>.</li>
  <li><b>Forward Edge</b>: (<i>u</i>,<i>v</i>), where <i>v</i> is a descendant of <i>u</i> but not a
  tree edge.</li>
  <li><b>Cross Edge</b>: any other edge. They can go between vertices in the same depth-first tree
       or in  different depth-first trees.</li>
</ul>

<p>Here's a graph with edges classified, and redrawn to better see the structural roles of the different kinds of edges:</p>
<img src="Topic-14/Fig-22-5-DFS-properties-a.jpg">
<img src="Topic-14/Fig-22-5-DFS-properties-c.jpg">

<h3>DFS Properties</h3>

<p>These theorems show important properties of DFS that will be used later to show how DFS exposes
properties of the graph.</p> 

<h4>Parentheses Theorem</h4>

<p>After any DFS of a graph <i>G</i>, for any two vertices <i>u</i> and <i>v</i> in <i>G</i>,
exactly one of the following conditions holds:</p>
<ul>
  <li>The intervals [<i>u</i>.<i>d</i>, <i>u</i>.<i>f</i>] and [<i>v</i>.<i>d</i>,
      <i>v</i>.<i>f</i>] are entirely disjoint, and neither <i>u</i> nor <i>v</i> is a descendant of
      the other in the DFS forest.</li>
  <li>The interval [<i>u</i>.<i>d</i>, <i>u</i>.<i>f</i>] is contained entirely within the interval
      [<i>v</i>.<i>d</i>, <i>v</i>.<i>f</i>], and <i>u</i> is a descendant of <i>v</i> in a DFS
      tree. </li>
  <li>The interval [<i>v</i>.<i>d</i>, <i>v</i>.<i>f</i>] is contained entirely within the interval
      [<i>u</i>.<i>d</i>, <i>u</i>.<i>f</i>], and <i>v</i> is a descendant of <i>u</i> in a DFS
      tree. </li>
</ul>
<p>Essentially states that the <i>d</i> and <i>f</i> visit times are well nested. See text for
proof. For the above graph:</p>

<img src="Topic-14/Fig-22-5-DFS-properties-b.jpg"> <img src="Topic-14/Fig-22-5-DFS-properties-a.jpg">

<h4>Corollary: Nesting of Descendant's Intervals</h4>

<p>Vertex <i>v</i> is a <b><em>proper descendent</em></b> of vertex <i>u</i> in the DFS forest of a
graph iff <i>u</i>.<i>d</i> &lt; <i>v</i>.<i>d</i> &lt; <i>v</i>.<i>f</i> &lt; <i>u</i>.<i>f</i>.
(Follows immediately from parentheses theorem.)</p>

<p>Also, (<i>u</i>, <i>v</i>) is a <b><em>back edge</em></b> iff <i>v</i>.<i>d</i> &le;
<i>u</i>.<i>d</i> &lt; <i>u</i>.<i>f</i> &le; <i>v</i>.<i>f</i>; and a <b><em>cross edge</em></b>
iff <i>v</i>.<i>d</i> &lt; <i>v</i>.<i>f</i> &lt; <i>u</i>.<i>d</i> &lt; <i>u</i>.<i>f</i>. </p> 

<h4>White Path Theorem</h4>

<p>Vertex <i>v</i> is a descendant of <i>u</i> iff at time <i>u.d</i> there is a path from <i>u</i> to
<i>v</i> consisting of only white vertices (except for <i>u</i>, which was <i>just</i> colored
gray).</p>

<p>(Proof in textbook uses <i>v</i>.<i>d</i> and <i>v</i>.<i>f</i>. Metaphorically and due to its
depth-first nature, if a search encounters an unexplored location, all the unexplored territory
reachable from this location will be reached before another search gets there.)</p>

<h4>DFS Theorem</h4>

<p>DFS of an undirected graph produces only tree and back edges: never forward or cross edges.</p>

<p>(Proof in textbook uses <i>v</i>.<i>d</i> and <i>v</i>.<i>f</i>. Informally, this is because the
edges being bidirectional, we would have traversed the supposed forward or cross edge earlier as a
tree or back edge.)</p>

<!-- ------------------------------------------------------------ -->
<hr><h2> Topological Sort </h2>

<p>A <b>directed acyclic graph</b> (DAG) is a good model for processes and structures that have
partial orders: You may know that <i>a</i> &gt; <i>c</i> and <i>b</i> &gt; <i>c</i> 
but may not have information on how <i>a</i> and <i>b</i> compare to each other.</p>

<p>One can always make a <b>total order</b> out of a partial order. This is what topological sort
does. A <b>topological sort</b> of a DAG is a linear ordering of vertices such that if (<i>u</i>,
<i>v</i>) &in; <i>E</i> then <i>u</i> appears somewhere before <i>v</i> in the ordering.</p>

<h3>Outline of Algorithm:</h3> 

<tt>Topological-Sort(G)</tt> is actually a modification of <tt>DFS(G)</tt> in which each vertex
<i>v</i> is inserted onto the front of a linked list as soon as finishing time <i>v</i>.<i>f</i> is
known. 

<h3>Examples</h3>

<p>Some real world examples include</p> 
<ul>
  <li> Scheduling 100,000 independent tasks on a high performance computing system (research by
       Dr. Henri Casanova) </li> 
  <il> Producing 5,000,000 documents that reference each other such that each document is produced before
       the ones that reference it.  </li> 
</ul>

<p>Here is the book's example ... a hypothetical professor (not me!) getting dressed <i>(what node
did they start the search at? Could it have been done differently?)</i>:</p> 
<img src="Topic-14/Fig-22-7-topological-sort.jpg">

<p>We can make it a bit more complex, with catcher's outfit (click to compare your answer): </p> 
<a href="Topic-14/DAG-topological-sort-example-2.jpg"><img src="Topic-14/DAG-topological-sort-example-1.jpg"></a>

<p><i>The answer given starts with the batting glove and works left across the unvisted nodes. What
if we had started the search with socks and worked right across the top nodes?  If you put your
clothes on differently, how could you get the desired result? Hint: add an edge.</i></p>

<p>As noted previously, one could start with any vertex, and once the first tree was constructed continue with
any artibrary remaining vertex. It is not necessary to start at the vertices at the top of the
diagram. <i>Do you see why?</i> </p>

<img src="Topic-14/pseudocode-topological-sort.jpg" align = "right">

<h3>Time Analysis</h3>

<p>Time analysis is based on simple use of DFS: &Theta;(<i>V</i> + <i>E</i>).</p>

<h3>Correctness</h3> 

<p><b><i>Lemma</i></b>: A directed graph <i>G</i> is acyclic iff a DFS of <i>G</i> yields no back
edges. </p>

<p> See text for proof, but it's quite intuitive:</p>
<blockquote>
&rArr; A back edge by definition is returning to where one started, which means it completes a
cycle. <br>
&lArr; When exploring a cycle the last edge explored
will be a return to the vertex by which the cycle was entered, and hence classified a back
edge.
</blockquote> 

<p><b><i>Theorem:</i></b> If <tt>G</tt> is a DAG then <tt>Topological-Sort(G)</tt> correctly
produces a topological sort of <tt>G</tt>.

<p>It sufficies to show that</p>

<blockquote>
if (<i>u</i>, <i>v</i>) &in; <i>E</i> then <i>v.f</i> &lt; <i>u.f</i>
</blockquote>

<p> because then the linked list ordering by <i>f</i> will respect the graph topology).</p>

<p>When we explore (<i>u</i>, <i>v</i>), what are the colors of <i>u</i> and <i>v</i>? </p>
<ul>
  <li><i>u</i> is gray, because it is being explored when (<i>u</i>, <i>v</i>) is found. </li>
  <li>Can <i>v</i> be gray too? No, because then <i>v</i> would be an ancestor of <i>u</i>, meaning
      (<i>u</i>, <i>v</i>) is a back edge, contradicting the DAG property by the lemma above.</li>
  <li>Is <i>v</i> white? Then it becomes a descendant of <i>u</i>. By the parentheses theorem,
      <i>u.d</i> &lt; <i>v.d</i> &lt;<b><i>v.f</i> &lt; <i>u.f</i></b>. </li>
  <li>Is <i>v</i> black? Then <i>v</i> is finished. Since we are exploring (<i>u</i>, <i>v</i>) we
      have not finished <i>u</i>. Therefore <b><i>v.f</i> &lt; <i>u.f</i></b>.</li>
</ul>
      
<!-- ------------------------------------------------------------ -->
<hr><h2> Strongly Connected Components </h2>

<p>Given a directed graph <i>G</i> = (<i>V</i>, <i>E</i>), a <b>strongly connected component
(SCC)</b> of <i>G</i> is a maximal set of vertices <i>C</i> &sube; <i>V</i> such that for all
<i>u</i>, <i>v</i> &in; <i>C</i>, there is a path both from <i>u</i> to <i>v</i> and from <i>v</i>
to <i>u</i>.</p>

<h4>Example:</h4> 
<p>What are the Strongly Connected Components? (Click to see.) </p>
<a href="Topic-14/SCC-example-1.jpg"><img src="Topic-14/SCC-example-0.jpg"></a> 

<h3>Algorithm</h3>

<p>The algorithm uses <i>G<sup>T</sup></i>= (<i>V</i>, <i>E<sup>T</sup></i>), the <b>transpose</b>
of <i>G</i> = (<i>V</i>, <i>E</i>). <i>G<sup>T</sup></i> is <i>G</i> with all the edges
reversed.</p>

<pre>
Strongly-Connected-Components (G)
1.  Call DFS(G) to compute finishing times <i>u</i>.<i>f</i> for each vertex <i>u</i> &in; <i>E</i>. 
2.  Compute <i>G<sup>T</sup></i>
3.  Call modified DFS(<i>G<sup>T</sup></i>) that considers vertices
    in order of decreasing <i>u</i>.<i>f</i> from line 1.
4.  Output the vertices of each tree in the depth-first forest
    formed in line 3 as a separate strongly connected component. 
</pre> 

<h3>Example 1</h3> 

<h4>First Pass of DFS:</h4> 
<img src="Topic-14/Fig-22-9-SCC-by-DFS-a.jpg">
<h4>Second Pass of DFS:</h4> 
<img src="Topic-14/Fig-22-9-SCC-by-DFS-b.jpg">

<!-- ------------------- --> 
<h3>Why it Works</h3>

<h4>Informal Explanation</h4>

<p><i>(This is from my own attempt to understand the algorithm. It differs from the book's formal
proof.)</i></p>

<p><i>G</i> and <i>G<sup>T</sup></i> have the same SCC. &nbsp; &nbsp; <i>Proof:</i></p>
<ul>
  <li>If <i>u</i> and <i>v</i> are in the same SCC in <i>G</i>, then there is a path
      <i>p</i><sub>1</sub> from <i>u</i> to <i>v</i> and a path <i>p</i><sub>2</sub> from <i>v</i>
      to <i>u</i>.</li>
  <li>Reversing the edges, path <i>p</i><sub>1</sub> becomes a path from <i>v</i> to <i>u</i> and
      <i>p</i><sub>2</sub> becomes a path from <i>u</i> to <i>v</i>.</li>
</ul>

<p>A DFS from any vertex <i>v</i> in a SCC <i>C</i> will reach <i>all</i> vertices in <i>C</i> (by
definition of SCC).</p>
<ul>
  <li>Then why can't we call DFS on unvisited vertices to find the SCCs in the first pass, line 1? </li>
  <li>Because this first unconstrained DFS could also get vertices <i>not</i> in <i>C</i>, as there
      may be a path from <i>v</i> in <i>C</i> to <i>v'</i> where there is no path from <i>v'</i> to
      <i>v</i> (so <i>v'</i> is not in <i>C</i>)!</li>
</ul>

<p>So how does the second search on <i>G<sup>T</sup></i> help avoid inadvertent inclusion of
<i>v'</i> in <i>C</i>? </p>
<ul>
  <li><i>v'</i> will have an earlier finishing time than some of the other vertices in <i>C</i>,
    because at least some of those vertices (in particular, <i>v</i> from which <i>v'</i> was
    reached) are still active (gray) when <i>v'</i> is finished (Parentheses Theorem). </li>
  <li> In the second search, the component <i>C</i> to which <i>v</i> belongs is processed before
    <i>v'</i> and its component,
    because <i>v</i> has a later finishing time, so the entire component will be
    explored before other components (in particular, that containing <i>v'</i>). </li>
  <li>Since <i>G<sup>T</sup></i> has the same SCC as <i>G</i>, the component found from <i>v</i>
    in the second search is the same component as in the previous search. </li>
  <li>But in this second search, <i>v'</i> will <em>not</em> be reached. Why? Because we are using
    reversed edges in <i>G<sup>T</sup></i>. If <i>v'</i> could be reached from <i>C</i> in
    <i>G<sup>T</sup></i>, then <i>v</i> would be reachable from <i>v'</i> in <i>G</i>, and so
    <i>v'</i> would be a  member of <i>C</i>, a contradiction.</li>
  <li> So, due to the topological sort, the trees constructed in the second search cannot contain
    vertices  <i>v'</i> that do not belong to the SCC of the other vertices in the tree. This along
    with the fact  that any DFS from
    a vertex <i>v</i> in a SCC <i>C</i> will find <i>all</i> vertices in <i>C</i> means that the
    trees constructed by the second DFSs find exactly the vertices in the SCCs.</li> 
</ul>

<p>In the example above, notice how node <i>c</i> corresponds to <i>v</i> and <i>g</i> to <i>v'</i>
in the argument above. But we need to also say why nodes like <i>b</i> will never be reached from
<i>c</i> in the second search. It is because <i>b</i> finished later in the first search, so was
processed earlier and already "consumed" by the correct SCC in the second search, before the search
from <i>c</i> could reach it. The following fact is useful in understanding why this would be the
case. </p>

<h4>Component Graph</h4> 
<ul>
  <li> Define <i>G<sup>SCC</sup></i> to be a graph of the SCCs of G obtained by collapsing all the 
       vertices in each SCC into one vertex for the component but retaining the edges between
       SCCs.</li>
  <li> Then this <b>component graph <i>G<sup>SCC</sup></i> is a Directed Acyclic Graph</b>. (If
       there were any cycles, vertices in each component would be reachable from all others, so they
       would be one component.) </li> 
</ul>

<p>Here is <i>G<sup>SCC</sup></i> for the above example: </p>
<img src="Topic-14/Fig-22-9-SCC-by-DFS-c.jpg">

<p>The first pass of the SCC algorithm essentially does a topological sort of the graph
<i>G<sup>SCC</sup></i> (by doing a topological sort of constituent vertices). The second pass visits
the components of <i>G<sup>T<sup>SCC</sup></sup></i> in topologically sorted order such that
<b><i>each component is searched before any component that can reach that component</i></b>.</p>

<p> Thus, for example, the component <i>abe</i> is processed first in the second search, and since
this second search is of <i>G<sup>T</sup></i> (reverse the arrows above) one can't get to <i>cd</i>
from <i>abe</i>. When <i>cd</i> is subsequently searched, one can get to <i>abe</i> but it's
vertices have <i>already been visited</i> so can't be incorrectly included in <i>cd</i>.  </p>

<h3>Example 2</h2>
<p>Start at the node indicated by the arrow; conduct a DFS; then click to compare your answer:</p>
<a href="Topic-14/SCC-example-2.jpg"><img src="Topic-14/SCC-example-0-start.jpg"></a> 

<h3>Analysis</h3>

<p>We have provided an informal justification of correctness: please see the CLRS book for a formal proof
of correctness for the SCC algorithm.</p>

<img src="Topic-14/pseudocode-SCC.jpg">

<p>The CLRS text says we can create <i>G<sup>T</sup></i> in &Theta;(<i>V</i> + <i>E</i>) time using
adjacency lists. </p>
<ul>
  <li>The easy approach is to simply copy the graph, but given the size of some graphs we
work with, it would be much better to reverse the edges in place (and reverse them back when
done). </li>
  <li><i> Problem for class: How can this be done? (A naive implementation could end up undoing
some of its own work, as it confuses already-reversed edges with those to be reversed.)</i></li> 
</ul>

<p>The SCC algorithm also has two calls to DFS, and these are &Theta;(V + E) each.</p>

<p>All other work is constant, so the overall time complexity is &Theta;(V + E).</p>

<!-- ------------------------------------------------------------ -->
<hr><h2> Related Graph Concepts</h2>

<img src="Topic-14/Fig-22-10-articulations-bridges-biconnected.jpg">

<p>An <b>articulation point</b> or <b>cut vertex</b> is a vertex that when removed causes a
(strongly) connected component to break into two components.</p>

<p>A <b>bridge</b> is an edge that when removed causes a (strongly) connected component to break
into two components. </p>

<p> A <b>biconnected component</b> is a maximal set of edges such that any two edges in the set lie
on a common simple cycle. This means that there is no bridge (at least two edges must be removed to
disconnect it). This concept is of interest for network robustness.</p>

<!-- ------------------------------------------------------------ -->
<hr><h2> Up Next</h2>

<p>We take a brief diversion from graphs to introduce amortized analysis and efficient processing of
union and find operations on sets, both of which will be used in subsequent work on graphs. Then we
return to graphs with concepts of minimum spanning trees, shortest paths, and flows in
networks. </p> 

<!-- ------------------------------------------------------------ -->
<hr>
<address>Dan Suthers</address>
<!-- hhmts start -->Last modified: Sat Mar 14 02:30:28 HST 2015 <!-- hhmts end -->
<br>Some images are from the instructor's material for Cormen et al. Introduction to Algorithms,
Third Edition.</br> 
</body>
</html>
