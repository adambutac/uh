<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html> <head>
<title>ICS 311 #17: Minimum Spanning Trees</title>
</head>

<body>

<hr><h1><a href="../index.html">ICS 311</a> #17: Minimum Spanning Trees </h1><hr> 

<!-- ------------------------------------------------------------ -->
<h2>Outline</h2>

<ol>
  <li>Minimum Spanning Trees </li>
  <li>Generic Algorithm and Safe Edge Theorem </li>
  <li>Kruskal's Algorithm </li>
  <li>Prim's Algorithm </li>
</ol>

<h2>Readings and Screencasts</h2>
<ul>
  <li>Required: CLRS 3rd Ed. Chapter 23, entire chapter.</li>
  <li>See also: Sedgewick (1984) Chapter 31 for light conceptual introduction (in Laulima),
    or Sedgewick & Wayne (2001) Algorithms Chapter 4 for code and application examples.</li> 
  <li>Screencasts <a href="http://youtu.be/Mx-dvvSE4Qc">17 A Intro</a>, 
                  <a href="http://youtu.be/1BnpXYm7LKY">17 B Kruskal</a>,
                  <a href="http://youtu.be/qegY0R78QMQ">17 C Prim</a>.
</ul>

<!-- ------------------------------------------------------------ -->
<hr><h2> Minimum Spanning Trees </h2>

<h3>Spanning Trees</h3>

<p>A <b>spanning tree</b> <i>T</i> for a connected graph <i>G</i> is a tree that includes all the
vertices of <i>G</i>: it <em>spans</em> the graph. </p>

<p>Without calling them such, we have already encountered two kinds of spanning trees in the
introduction to graphs (<a href="Topic-14.html">Topic 14</a>): those generated by breadth-first
search and depth-first search. We saw that <em> breadth-first trees </em> are one way of finding
shortest paths in a graph, and <em> depth-first forests </em> (a collection of spanning trees, one
for each connected component) are good for uncovering the structure of a graph such as topological
sort and connectivity. These were defined on unweighted graphs.</p>

<h3>Minimum Spanning Trees</h3>

<p>Many application areas (e.g., in communications, electronics, and transportation) require finding
the lowest cost way to connect a set of objects or locations. For example, the cost may be measured
in terms of currency or distance. We can model such situations with <i><b>weighted graphs</b></i>,
introduced in <a href="Topic-14.html">Topic 14</a> as graphs where a real-valued number is
associated with each edge. Then we want to find a spanning tree of minimum cost. </p>

<p>More formally, we can pose this as a problem on a graph representation <i>G</i> = (<i>V</i>,
<i>E</i>): </p> 
<ul>
  <li> The objects or locations are vertices <i>V</i> and the available connections are edges
       <i>E</i>.</li>
  <li> A weight function <i>w</i>(<i>u</i>,<i>v</i>) gives the weight on each edge
       (<i>u</i>,<i>v</i>) &in; <i>E</i>.</li>
  <li> We seek <i>T</i> &sube; <i>E</i> such that
       <ul>
         <li> <i>T</i> connects all the vertices <i>V</i> of <i>G</i>. </li>
         <li> The sum of weights <i>w</i>(<i>T</i>) =
         <big>&Sigma;</big><sub>(<i>u</i>,<i>v</i>)&in;<i>T</i></sub> <i>w</i>(<i>u</i>,<i>v</i>) is
         minimized. </li>
       </ul>
  </li> 
</ul>

<p>A few facts can be noted: </p>
<ul>
  <li><i>G</i> must be connected (consist of a single connected component) in order for <i>T</i> to
      be possible. </li>
  <li>However, if <i>G</i> is not connected we can generalize the problem to one of
      finding <i>T</i><sub>1</sub> ... <i>T<sub>c</sub></i> for each of <i>c</i> connected
      components of <i>G</i>.</li>
  <li>A subgraph of <i>G</i> that connects its vertices <i>V</i> at minimal cost will always be a
      tree. <i>Why?</i></li> 
</ul>

<p>Therefore we call this the <b>minimum spanning tree (MST)</b> problem (and the generalized
version the minimum spanning forest problem).</p> 

<p>Here is an example of a minimum spanning tree (the shaded edges represent <i>T</i>):</p>

<img src="Topic-17/example-MST-1.jpg">

<p><i>Are minimum spanning trees unique?</i></p> 
<p>Look at edges (<i>e</i>,<i>f</i>) and (<i>c</i>,<i>e</i>).</p>

<!-- ------------------------------------------------------------ -->
<hr><h2> Generic Algorithm and Safe Edge Theorem</h2>

<p>We specify a generic greedy algorithm for solving the MST problem. The algorithm will be "greedy"
in terms of always choosing a lowest cost edge. This algorithm is instantiated into two versions,
Kruskal's and Prim's algorithms, which differ in how they define from what set of edges the lowest
cost edge is chosen.</p>

<p>Let's start by noting some properties that MSTs of <i>G</i> = (<i>V</i>, <i>E</i>) have</p>
<ul>
  <li>A MST for <i>G</i> has |<i>V</i>| &minus; 1 edges. (See properties of trees, <a
      href="Topic-08.html">Topic 8</a>.)</li> 
  <li>Any tree (and hence any MST) has no cycles. It has only one path between any two vertices.</li>
  <li>There might be more than one MST for <i>G</i>.</li>
</ul>

<h3>Building a Solution</h3> 
<ul>
  <li>We will build a set of edges <i>A</i>. </li>
  <li>Initially <i>A</i> has no edges.</li>
  <li>As we add edges to <i>A</i>, we maintain a loop invariant: <i>A</i> is a subset of
      <em>some</em> MST for <i>G</i>.</li>
</ul>

<p>Define an edge (<i>u</i>,<i>v</i>) to be <b>safe</b> for <i>A</i> iff <i>A</i> <big>&cup;</big>
{(<i>u</i>,<i>v</i>)} is also a subset of some MST for <i>G</i>.</p> 
<small><p>(BTW, "iff" is not a spelling error: it is shorthand for "if and only if" commonly used in
proofs.</p></small>

<p>If we only add safe edges to <i>A</i>, once |<i>V</i>| &minus; 1 edges have been added we
have a MST for <i>G</i>. This motivates the following algorithm.</p>

<h3>Generic MST Algorithm</h3> 
<img src="Topic-17/pseudocode-generic-MST.jpg">
<p><i>Loop Invariant:</i> <i>A</i> is a subset of some MST for <i>G</i></p> 
<ul>
  <li><i>Initialization:</i> The initially empty set trivially satisfies the loop invariant.</li>
  <li><i>Maintenance:</i> Since we add only safe edges, <i>A</i> remains a subset of some MST.</li>
  <li><i>Termination:</i> We stop when <i>A</i> is a spanning tree (|<i>A</i>| = |<i>V</i>| &minus; 1), and
     it is a subset of itself.</li>  
</ul>
<p>OK, great, but how do we find safe edges?</p>

<h3>Finding Safe Edges</h3> 

<p>Each time we add an edge we are connecting two sets of vertices that were not previously
connected by <i>A</i>. (Otherwise we would be forming a cycle.) A greedy algorithm might try to keep
the cost down by choosing the lowest cost edge that connects previously unconnected
vertices. (Perhaps we should call it a "stingy" algorithm!)

<p> But is this greedy strategy "safe"? How do we know that after adding this edge we still have a
subset of an MST? </p>

<p>First some definitions:</p>
<ul>
  <li>A <b>cut</b> (<i>S</i>, <i>V</i> &minus; <i>S</i>) is a partition of vertices into disjoint sets
      <i>S</i> and <i>V</i> &minus; <i>S</i>. </li>
  <li>Edge (<i>u</i>,<i>v</i>) &in; <i>E</i> <b>crosses</b> cut (<i>S</i>, <i>V</i> &minus; <i>S</i>) if one
      endpoint is in <i>S</i> and the other is in <i>V</i> &minus; <i>S</i>. </li>
  <li>A cut <b>respects</b> <i>A</i> iff no edge in <i>A</i> crosses the cut.</li>
  <li>An edge is a <b>light edge</b> crossing a cut iff its weight is minimum over all edges
      crossing the cut. (There may be more than one light edge for a given cut.) </li>
</ul> 

<p>The following figure illustrates a cut and will be used in the proof below. There are two sets of
vertices <i>S</i> and <i>V</i> &minus; <i>S</i>. Four edges cross the cut (<i>S</i>, <i>V</i> -
<i>S</i>). Whether or not this respects <i>A</i> depends on what is in <i>A</i>.</p>

<img src="Topic-17/illustration-safe-edge-theorem.jpg" align = "right">

<p><i>Suppose A = {(u,v) such that u &in; S and v &in; S}. Does the cut (<i>S</i>, <i>V</i> -
<i>S</i>) depicted in the figure respect A?</p>

<p>Now suppose A is the shaded edges in the figure. Does the cut (<i>S</i>, <i>V</i> -
<i>S</i>) respect A?</i></p> 

<h4>Safe Edge Theorem</h4>
<p>Let <i>G</i> = (<i>V</i>, <i>E</i>) be a graph, <i>A</i> be a subset of some MST for <i>G</i>,
(<i>S</i>, <i>V</i> &minus; <i>S</i>) be a cut that respects <i>A</i>, and (<i>u</i>,<i>v</i>) be a light
edge crossing (<i>S</i>, <i>V</i> &minus; <i>S</i>). Then (<i>u</i>,<i>v</i>) is safe for <i>A</i>.</p>

<p>(<i>Paraphrased: A light edge that crosses a cut that respects <i>A</i> is safe for <i>A</i>.</i>)</p> 

<p><i><b>Proof:</b></i> Let <i>T</i> be a MST that includes <i>A</i>. Consider two cases: </p>

<p>Case 1: <i>T</i> contains (<i>u</i>,<i>v</i>). Then the theorem is proven, since <i>A</i>
<big>&cup;</big> {(<i>u</i>,<i>v</i>)} &sube; <i>T</i> is a subset of some MST for <i>G</i>. </p>

<p>Case 2: <i>T</i> does not contain (<i>u</i>,<i>v</i>). We will show that we can construct a tree
<i>T'</i> that is a MST for <i>G</i> and that contains <i>A</i> <big>&cup;</big>
{(<i>u</i>,<i>v</i>)}.</p>

<img src="Topic-17/illustration-safe-edge-theorem.jpg" align = "right">

<p>Since <i>T</i> is a tree it contains a unique path <i>p</i> between <i>u</i> and <i>v</i>. Path
<i>p</i> must cross the cut (<i>S</i>, <i>V</i> &minus; <i>S</i>) at least once (otherwise <i>T</i> would be
disconnected). Let (<i>x</i>,<i>y</i>) be an edge of <i>p</i> that crosses the cut.</p> 

<small><p>(Except for the dashed edge (<i>u</i>,<i>v</i>), all the edges shown in the figure are in
<i>T</i>. <i>A</i> is not shown in the figure, but it cannot contain any edges that cross the cut,
since the cut respects <i>A</i>. Shaded edges are the path <i>p</i>.)</p></small>

<p>Since the cut respects <i>A</i>, edge (<i>x</i>,<i>y</i>) is not in <i>A</i>. </p>

<p>To form <i>T'</i> from <i>T</i>: Remove (<i>x</i>,<i>y</i>). This breaks <i>T</i> into two
components. Add (<i>u</i>,<i>v</i>). This reconnects the tree. So <i>T'</i> = T -
{(<i>x</i>,<i>y</i>)} <big>&cup;</big> (<i>u</i>,<i>v</i>) is a spanning tree.</p>

<p>To show that <i>T'</i> is a minimal spanning tree: <i>w</i>(<i>T'</i>) = <i>w</i>(<i>T</i>) -
<i>w</i>(<i>x</i>,<i>y</i>) + <i>w</i>(<i>u</i>,<i>v</i>) &le; <i>w</i>(<i>T</i>) since
(<i>u</i>,<i>v</i>) is light. </p>

<p>We still need to show that (<i>u</i>,<i>v</i>) is safe for <i>A</i>. Since <i>A</i> &sube;
<i>T</i> and (<i>x</i>,<i>y</i>) &notin; <i>A</i> then A &sube; <i>T'</i>. Therefore <i>A</i>
<big>&cup;</big> {(<i>u</i>,<i>v</i>)} &sube; <i>T'</i>, a MST. &diams;</p>

<h4>Further Observations</h4>

<p> <i>A</i> is a forest containing connected components. Initially each component is a single
vertex. Any safe edge merges two of these components into one. Each component so constructed is a
tree. Since an MST has exactly |<i>V</i>| &minus; 1 edges, the loop iterates |<i>V</i>| &minus; 1 times before
we are down to one component.</p> 

<h4>Corollary</h4>

<p> If <i>C</i> = (<i>V<sub>C</sub></i>, <i>E<sub>C</sub></i>) is a connected component in the
forest <i>G<sub>A</sub></i> = (<i>V</i>, <i>A</i>) and (<i>u</i>,<i>v</i>) is a light edge
connecting <i>C</i> to some other component <i>C'</i> in <i>G<sub>A</sub></i> -- that is,
(<i>u</i>,<i>v</i>) is a light edge crossing the cut (<i>V<sub>C</sub></i>, <i>V</i> -
<i>V<sub>C</sub></i>) -- then (<i>u</i>,<i>v</i>) is safe for <i>A</i>.</p>

<p><i>Proof:</i> Set <i>S</i> = <i>V<sub>C</sub></i> in the theorem. &diams; </p> 

<p>This idea (of thinking in terms of components rather than vertices) leads to Kruskal's algorithm
...</p> 

<!-- ------------------------------------------------------------ -->
<hr><h2> Kruskal's Algorithm </h2>

<p>Kruskal's algorithm starts with each vertex being its own component, and repeatedly merges two
components into one by choosing the light edge that connects them. It does this greedily (or
stingily?) by scanning the edges in increasing order by weight. A disjoint-set data structure is
used to determine whether an edge connects vertices in two different components.</p>

<p>This algorithm has similarities with the connected components algorithm we previously saw in <a
 href="Topic-16.html">Topic 16</a>:</p>
<img src="Topic-16/pseudocode-connected-components.jpg">

<p>Here is Kruskal's version:</p>
<img src="Topic-17/pseudocode-Kruskal-MST.jpg">

<h3>Example</h3> 
<p>Let's start with this example. The first edge has been chosen. </p> 
<img src="Topic-17/Fig-23-4-Kruskal-Example-a.jpg">
<p> Add 4 more edges (notice we could add edges of weight 2 in either order, and similarly for 4) ...</p>
<img src="Topic-17/Fig-23-4-Kruskal-Example-e.jpg">
<p>The next edge considered is not added because it would connect already connected vertices: </p>
<a href="Topic-17/Topic-17-K.html"> <img src="Topic-17/Fig-23-4-Kruskal-Example-f.jpg"></a> 
<p>Keep going until the MST is constructed, and click to see the final tree.</p>

<h3>Analysis</h3>
<img src="Topic-17/pseudocode-Kruskal-MST.jpg">
<p>The costs are:</p>
<ul>
  <li>Initialize <i>A</i>: O(1)</li>
  <li>First <tt>for</tt> loop: |<i>V</i>| <tt>MAKE-SET</tt> operations</li>
  <li>Sort <i>E</i>: O(<i>E</i> lg <i>E</i>) </li>
  <li>Second <tt>for</tt> loop: O(<i>E</i>) <tt>FIND-SETs</tt> and <tt>UNIONs</tt></li>
</ul>

<p>If we use the tree implementation of the disjoint-set data structure with union by rank and path
compression (<a href="Topic-16.html">Topic 16</a>), the amortized cost per <tt>MAKE-SET</tt>,
<tt>UNION</tt> and <tt>FIND-SET</tt> operation (across |<i>E</i>| operations) is
O(&alpha;(<i>V</i>)), where &alpha; is a <i>very</i> slowly growing function, the inverse of
Ackermann's function.  (Lemma 21.11 states that MAKE-SET in isolation is O(1), but here we must
treat it as O(&alpha;(<i>V</i>)) since we are making a statement about the amortized cost per
operation in a <u>sequence</u> of <i>m</i> operations: see section 24.1. Also, using
O(&alpha;(<i>V</i>)) simplifies the expression below.)</p>

<p>Droping the lower order O(1) and substituting &alpha;(<i>V</i>) for the disjoint-set operations,
the above list of costs sums to O((<i>V</i> + <i>E</i>)&sdot;&alpha;(<i>V</i>))+ O(<i>E</i> lg
<i>E</i>). </p>

<p>Since G is connected, |<i>E</i>| &ge; |<i>V</i>| &minus; 1, so we can replace <i>V</i> with
<i>E</i> to simplify the first term for the disjoint-set
operations, O((<i>V</i> + <i>E</i>)&sdot;&alpha;(<i>V</i>)), to O((<i>E</i>
+ <i>E</i>)&sdot;&alpha;(<i>V</i>)) or O(<i>E</i>&sdot;&alpha;(<i>V</i>)).</p>

<p>Furthermore, &alpha;(<i>V</i>) = O(lg <i>V</i>) = O(lg <i>E</i>), so
O(<i>E</i>&sdot;&alpha;(<i>V</i>)) is O(<i>E</i> lg <i>E</i>), and hence the entire expression we
started with, O((<i>V</i> + <i>E</i>)&sdot;&alpha;(<i>V</i>))+ O(<i>E</i> lg <i>E</i>), simplifies
to O(<i>E</i> lg <i>E</i>). </p>

<p>Finally, since |<i>E</i>| &le; |<i>V</i>|<sup>2</sup>, lg |<i>E</i>| = O(2 lg <i>V</i>) = O(lg
<i>V</i>), so we can write the result as <b>O(<i>E</i> lg <i>V</i>)</b> to obtain the growth rate in
terms of both |<i>E</i>| and |<i>V</i>|.

<p>(It is usually a good idea to include both <i>V</i> and <i>E</i> when giving growth rates for
graph algorithms, unless one of them can be strictly limited to the other. Shortly we will see that
O(<i>E</i> lg <i>V</i>) enables comparison to Prim's algorithm.) </p>


<!-- ------------------------------------------------------------ -->
<hr><h2> Prim's Algorithm </h2>

<p>This algorithm is also a greedy (stingy) algorithm, but it builds one tree, choosing the lightest
edge incident on the growing tree, so the set <i>A</i> is always a tree. The tree is initialized to
be a single vertex, designated <i>r</i> for root.</p>

<p>At each step it finds a light edge crossing the cut (<i>V<sub>A</sub></i>, <i>V</i> -
<i>V<sub>A</sub></i>), where <i>V<sub>A</sub></i>= vertices that are incident on <i>A</i>, and adds
this edge to <i>A</i>. (Initially, <i>A</i> = {} and <i>V<sub>A</sub></i> = {<i>r</i>}.)</p>

<img src="Topic-17/illustration-Prims-algorithm.jpg">
<p>(Edges of <i>A</i> are shaded in the illustration.)</p>

<h3>General Idea</h3> 
<p>To find the light edge quickly we use a priority queue <i>Q</i> (<a href="Topic-09.html">Topic
09</a>):</p>
<ul>
  <li>Each queued object is a vertex in <i>V</i> &minus; <i>V<sub>A</sub></i> (the vertices that have not
      yet been connected to <i>A</i>). </li> 
  <li>The key is the minimum weight of any edge (<i>u</i>,<i>v</i>) where <i>u</i> &in;
      <i>V<sub>A</sub></i>. (We update this weight for <i>v</i> whenever a new edge is found that
      reaches <i>v</i> at a lower cost than before.)  </li>
  <li>Thus the vertex returned by <tt>EXTRACT-MIN</tt> is for <i>v</i> such that &exist; <i>u</i>
      &in; <i>V<sub>A</sub></i> and (<i>u</i>,<i>v</i>) is a light edge crossing (<i>V<sub>A</sub></i>, <i>V</i> -
      <i>V<sub>A</sub></i>). </li>
  <li>If <i>v</i> is not adjacent to any vertices in <i>V<sub>A</sub></i>, the key of <i>v</i> is
      &infin; </li> 
</ul>

<p> The edges of <i>A</i> will form a rooted tree with root <i>r</i>, given as input (<i>r</i> can be any
      vertex). </p> 
<ul> 
  <li>Each vertex keeps track of its parent by the attribute <i>v</i>.&pi; = parent of <i>v</i>, or
      NIL if <i>v</i> = <i>r</i> or has no parent yet.</li>
  <li>As the algorithm progresses, <i>A</i> = {(<i>v</i>, <i>v</i>.&pi;) : <i>v</i> &in; <i>V</i> -
      {<i>r</i>} &minus; <i>Q</i>}. </li>
  <li> At termination, <i>Q</i> is empty, so <i>A</i> is a MST.</li> 
</ul>

<h3>Pseudocode</h3>
<p>This code <u>differs from the book's version</u> in having explicit calls to the heap methods:</p> 
<img src="Topic-17/pseudocode-Prim-MST-improved.jpg">

<p>Notice that it is possible for the last <tt>if</tt> to execute multiple times for a given
<i>v</i>. In other words, we may find an edge reaching vertex <i>v</i>, but before we choose to use
it (because other edges have lower key values), we find another edge reaching <i>v</i> for lower
cost (key value). <i>Watch for this situation in the example below.</i></p>

<h3>Example</h3>
<p>Let's try it with this graph. The first three steps are shown. Every time a vertex is dequed, it
is colored black and the cost of all adjacent vertices are updated as needed. For example, when
<b>a</b> is dequeued, the cost of <b>b</b> is updated from infinite to 4, and the cost of <b>h</b>
is updated from infinite to 8. Then when <b>b</b> is dequeued, its neighbors are updated and so on.</p> 
<a href="Topic-17/Fig-23-5-Prim-Example-i.jpg"><img
src="Topic-17/Fig-23-5-Prim-Example-a-d.jpg"></a>

<p><i>Did you see where a vertex's key was lowered from one non-infinite value to another? Which
one? </i></p>

<p><i>Now finish it and click on the image to see final solution.</i></p>

<img src="Topic-17/pseudocode-Prim-MST-improved.jpg" align = "right">
<h3> Analysis </h3>
<p>Performance depends on the priority queue implementation. With a binary heap implementation (<a
href="Topic-09.html">Topic 09</a>), the costs are:</p>
<ul>
  <li>Initialize <i>Q</i> and iterate over |<i>V</i>| vertices in first <tt>for</tt> loop to insert
      in queue, each insert being O(lg <i>V</i>): O(<i>V</i> lg <i>V</i>) total.</li>
  <li>Decrease key of r: O(lg <i>V</i>)</li>
  <li>The <tt>while</tt> loop has |<i>V</i>| <tt>EXTRACT-MIN</tt> calls &rarr; O(<i>V</i> lg
  <i>V</i>)</li>
  <li>By aggregate analysis, the inner <tt>for each</tt> loop processes &Theta;(|<i>E</i>|) edges, 
      O(<i>E</i>) of which result in O(lg <i>V</i>) <tt>DECREASE-KEY</tt> calls &rarr; O(<i>E</i> lg
      <i>V</i>)</li> 
</ul>
<p> The sum of the dominating terms is O(<i>V</i> lg <i>V</i>) + O(<i>E</i> lg <i>V</i>).</p>

<p> If G is connected, |<i>E</i>| &ge; |<i>V</i>| &minus; 1, so we can replace O(<i>V</i> lg <i>V</i>)
with O(<i>E</i> lg <i>V</i>), and the total is <b>O(<i>E</i> lg <i>V</i>)</b>.</p>

<p>This is asympotitically the same as Kruskal's algorithm. A faster implementation of O(<i>E</i> +
<i>V</i> lg <i>V</i>) is possible with Fibonacci Heaps, as explained in the text.</p>

<p><i>If your graph is not connected, which algorithm would correctly produce a forest of minimum
spanning trees, one for each connected component? How would you modify the other one to do this?</i>
</p>


<!-- ------------------------------------------------------------ -->
<hr>
<address>Dan Suthers</address>
<!-- hhmts start -->Last modified: Sun Apr  5 03:56:02 HST 2015 <!-- hhmts end -->
<br>Images are from the instructor's material for Cormen et al. Introduction to Algorithms, Third
Edition.</br> 
</body>
</html>
